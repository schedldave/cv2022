{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schedldave/cv2022/blob/main/HW03_Calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk92nT2wT4U8"
      },
      "source": [
        "# Computer Vision Homework 03 - Calibration\n",
        "\n",
        "Contact: David C. Schedl (david.schedl@fh-hagenberg.at)\n",
        "\n",
        "Note: this is the starter pack for the **Computer Vision** homework. You do not need to use this template!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMb4sAogUarc"
      },
      "source": [
        "## Task:\n",
        "Calibrate *your* camera to estimate intrinsic and distortion parameters and use it to get the extrinsic (rotation and translation) of a pair of images.\n",
        "\n",
        "You should:\n",
        " \n",
        "* first calibrate your camera with a standard calibration pattern (e.g., pictures of a checkerboard or a circle grid),\n",
        "* then record two images at varying camera positions and estimate the rotation and translation of image 1 to image 2 with the intrinsic calibration (the calibrated case) and without the intrinsic calibration (the uncalibrated case). \n",
        "\n",
        "Pick a camera that has some lens distortions (e.g., a fisheye lens, a webcam, or the front facing camera of your smartphone). \n",
        "Use low-resolution images to avoid too much computational overhead (e.g., downscale the images). \n",
        "After calibration discuss what the distortion parameters mean. How many parameters do you need?\n",
        "\n",
        "For the extrinsic estimation use images without a calibration pattern. However, you can design your own calibrated scene and use it for the extrinsic estimation. For example, you can place objects and measure object and camera positions to estimate the quality of the extrinsic calibration later. Make sure that you have strong interest points in your scene that can be found in both images.\n",
        "Use feature descriptors to find correspondences and match them. Matching can be done with the nearest neighbour distance or any other strategy. \n",
        "\n",
        "To estimate the extrinsic parameters, you can use OpenCV's [`findEssentialMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), [`findFundamentalMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), or any similar function. Using more than one image (pair) is allowed but might complicate things. \n",
        "\n",
        "Evaluate the calibration and the extrinsic parameter estimation with and without the intrinsic calibration first. Think about and discuss how you can measure how well the calibration worked. \n",
        "\n",
        "\n",
        "**Further comments/hints:**\n",
        "\n",
        "*   If your camera has severe distortions your calibration might need a lot of images. Don't worry too much about imprecisions. \n",
        "*   When estimating the extrinsic, make sure that your points are not on the same plane (especially in the uncalibrated case).\n",
        "*   Think about the problem ðŸ¤”, solve it, and critically evaluate your solution.\n",
        "*   Summarize your ideas and findings in the report. \n",
        "\n",
        "\n",
        "\n",
        "**Have fun!** ðŸ˜¸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j14w-SeSOC9k"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Let's import useful libraries, first. \n",
        "Then download some images or additional python scripts with `curl`.\n",
        "Let's define utility functions to display images, in Jupyter Notebooks. OpenCV's `imshow` does not work and matplotlib's `imshow` needs special treatment due to color channel handling (RGB vs. BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCnNG_BnJcnk",
        "outputId": "89d9c8ad-a41b-42d6-ecd1-c426d3403379"
      },
      "outputs": [],
      "source": [
        "# SETUP\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  # install a newer opencv version on Colab. The default does not support SIFT!\n",
        "  !pip install opencv-contrib-python==4.5.*\n",
        "\n",
        "# import the libraries we use\n",
        "import os\n",
        "import cv2 # openCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# loading some useful OpenCV files to create patterns:\n",
        "!curl -o \"gen_pattern.py\" \"https://raw.githubusercontent.com/opencv/opencv/4.x/doc/pattern_tools/gen_pattern.py\"\n",
        "!curl -o \"svgfig.py\" \"https://raw.githubusercontent.com/opencv/opencv/4.x/doc/pattern_tools/svgfig.py\"\n",
        "\n",
        " \n",
        "# loading an example image for an asymmetric circular grid.\n",
        "!curl -o \"acircles.png\" \"https://answers.opencv.org/upfiles/1466012643341173.png\"\n",
        "\n",
        "# utility function(s)\n",
        "def imshow(image, *args, **kwargs):\n",
        "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks using matplotlib.\n",
        "\n",
        "        Args:\n",
        "          image : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
        "            (N, M, 3) is an NxM BGR color image. \n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "      # Height, width, channels\n",
        "      # Assume BGR, do a conversion  \n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Draw the image\n",
        "    plt.imshow(image, *args, **kwargs)\n",
        "    # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
        "    plt.axis('off')\n",
        "    # Make sure it outputs\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcnl0Mc-K6kr"
      },
      "source": [
        "## Create a Calibration Pattern\n",
        "\n",
        "OpenCV provides function to create calibrations. See [this OpenCV documentation](https://docs.opencv.org/4.x/da/d0d/tutorial_camera_calibration_pattern.html).\n",
        "Be careful if you run the script in Windows make that the output path (`-o`) is absolute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JWPCQpocLF2e"
      },
      "outputs": [],
      "source": [
        "# Some example calibration patterns that can be generated with the gen_pattern.py file!\n",
        "!python gen_pattern.py -o chessboard.svg --rows 9 --columns 6 --type checkerboard --square_size 20\n",
        "!python gen_pattern.py -o circleboard.svg --rows 7 --columns 5 --type circles --square_size 15\n",
        "!python gen_pattern.py -o acircleboard.svg --rows 7 --columns 5 --type acircles --square_size 10 --radius_rate 2\n",
        "!python gen_pattern.py -o radon_checkerboard.svg --rows 10 --columns 15 --type radon_checkerboard -s 12.1 -m 7 4 7 5 8 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YucHEifrO5j8"
      },
      "source": [
        "## Detect circles in a circular calibration pattern\n",
        "\n",
        "We looked already at how to find the corners of a checkerboard. \n",
        "Another alternative is to use circles for calibration. \n",
        "OpenCV provides functions for finding circular grids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "e37eBglHPvN3",
        "outputId": "fca838e9-831e-473e-b835-f94a69041408"
      },
      "outputs": [],
      "source": [
        "def processImageCircles(img):\n",
        "    if img is None:\n",
        "        print(\"Image is None!\")\n",
        "        return None\n",
        "\n",
        "    # Setup SimpleBlobDetector parameters and the detector.\n",
        "    blobParams = cv2.SimpleBlobDetector_Params() # Todo: you might need to tune these parameters\n",
        "    detector = cv2.SimpleBlobDetector_create(blobParams)\n",
        "\n",
        "    # the shape of the pattern:\n",
        "    # test pattern has 7 columns and 10 rows\n",
        "    shape = (7,10)\n",
        "\n",
        "    # find the circles. \n",
        "    found, corners = cv2.findCirclesGrid( img, shape, \n",
        "          flags = cv2.CALIB_CB_ASYMMETRIC_GRID, blobDetector = detector )\n",
        "    \n",
        "    if found: # refine corner with sub-pixel accuracy\n",
        "        term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1)\n",
        "        corners = cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)\n",
        "\n",
        "    else : #not found!\n",
        "        print('circles not found')\n",
        "        return None\n",
        "\n",
        "    return corners.reshape(-1, 2)\n",
        "\n",
        "img = cv2.imread( 'acircles.png', cv2.IMREAD_GRAYSCALE )\n",
        "corners = processImageCircles( img )\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(15,10))\n",
        "imshow(img, cmap='gray')\n",
        "plt.plot(corners[:,0], corners[:,1], 'rx')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "HW03_Calibration.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0bae4c9257a18836fb2e3dc2d0aeb6355625d596c4075009294ab101cd3e0d3c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
