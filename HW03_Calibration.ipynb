{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk92nT2wT4U8"
      },
      "source": [
        "# Computer Vision Homework 03 - Calibration\n",
        "\n",
        "Contact: David C. Schedl (david.schedl@fh-hagenberg.at)\n",
        "\n",
        "Note: this is the starter pack for the **Computer Vision** homework. You do not need to use this template!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMb4sAogUarc"
      },
      "source": [
        "## Task:\n",
        "Calibrate *your* camera to estimate intrinsic and distortion parameters and use it to get the extrinsic (rotation and translation) of a pair of images.\n",
        "\n",
        "You should:\n",
        " \n",
        "* first calibrate your camera with a standard calibration pattern (e.g., pictures of a checkerboard or a circle grid),\n",
        "* then record two images at varying camera positions and estimate the rotation and translation of image 1 to image 2 with the intrinsic calibration (the calibrated case) and without the intrinsic calibration (the uncalibrated case). \n",
        "\n",
        "Pick a camera that has some lens distortions (e.g., a fisheye lens, a webcam, or the front facing camera of your smartphone). \n",
        "Use low-resolution images to avoid too much computational overhead (e.g., downscale the images). \n",
        "After calibration discuss what the distortion parameters mean. How many parameters do you need?\n",
        "\n",
        "For the extrinsic estimation use images without a calibration pattern. However, you can design your own calibrated scene and use it for the extrinsic estimation. For example, you can place objects and measure object and camera positions to estimate the quality of the extrinsic calibration later. Make sure that you have strong interest points in your scene that can be found in both images.\n",
        "Use feature descriptors to find correspondences and match them. Matching can be done with the nearest neighbour distance or any other strategy. \n",
        "\n",
        "To estimate the extrinsic parameters, you can use OpenCV's [`findEssentialMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), [`findFundamentalMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), or any similar function. Using more than one image (pair) is allowed but might complicate things. \n",
        "\n",
        "Evaluate the calibration and the extrinsic parameter estimation with and without the intrinsic calibration first. Think about and discuss how you can measure how well the calibration worked. \n",
        "\n",
        "\n",
        "**Further comments/hints:**\n",
        "\n",
        "*   If your camera has severe distortions your calibration might need a lot of images. Don't worry too much about imprecisions. \n",
        "*   Think about the problem ðŸ¤”, solve it, and critically evaluate your solution.\n",
        "*   Summarize your ideas and findings in the report. \n",
        "\n",
        "\n",
        "\n",
        "**Have fun!** ðŸ˜¸\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNW646RXIBlTlwLWXB7rhJB",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "HW03_Calibration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}